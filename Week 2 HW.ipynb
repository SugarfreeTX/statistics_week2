{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Homework: Loading data\n",
    "\n",
    "Create a new IPython Notebook and use it to answer the following assignments. Note that the **c** sections for each are meant to be a little more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Load the MovieData.csv dataset as described in this week's lesson, and use it to find the following values:\n",
    "\n",
    "a. What is the average US Gross of movies in the dataset?\n",
    "\n",
    "b. How many movies in the dataset have budgets greater than $20 million?\n",
    "\n",
    "c. How many movies were released by each film distributor? (Hint: this could be a good place to use dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Load the earthquake data in QuakeData.csv, and use it to answer the following questions:\n",
    "\n",
    "a. How many earthquakes are in the dataset?\n",
    "\n",
    "b. What is the average magnitude of earthquakes in the dataset?\n",
    "\n",
    "c. The DateTime format in this dataset is a bit trickier than it was for movies. Try to parse it into a datetime object. Do most earthquakes happen between midnight and noon, or noon to midnight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "In this question, you're asked to use what you've learned to analyze unstructured data -- a plain text file, *data.txt* containing the Facebook's description of its business in its [mandatory annual report to shareholders](http://investor.fb.com/secfiling.cfm?filingID=1326801-15-6) (called a Form 10K).\n",
    "\n",
    "**Bonus:** *sorted(...)* is a built-in Python function for sorting lists according to some order. For extra credit, figure out how to sort dictionary keys based on the values in descending order, and sort all your answers below. To read more about sorting, start at the Python documentation here:\n",
    "https://docs.python.org/3.5/howto/sorting.html#sortinghowto\n",
    "\n",
    "a) Read in the text in the file, and count how many times each individual word appears. For this exercise, words are separated by whitespace -- don't worry about colons, dashes, etc.\n",
    "\n",
    "b) [Stop words](https://en.wikipedia.org/wiki/Stop_words) are words that appear so often in a language that they aren't useful for analysis (you may have noticed them in your results for **a**). Below is a list of stop words taken from [NLTK](http://www.nltk.org/), the Natural Language Toolkit for Python. Read in the document and count words again -- but this time, convert all the words to lower-case, and only include the words that *aren't* on the stop word list. Also remove any punctuation (the characters .,?!-) from the beginning and end of words Finally, only output the words which appear more than once.\n",
    "\n",
    "c) Write the results of the previous section (including words that appear only once) to a csv file. There should be two columns, one for the word and the other for the count. For example:\n",
    "\n",
    "    Word,Count\n",
    "    million,2\n",
    "    objectives,1\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', \n",
    "'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
